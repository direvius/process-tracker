#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
Process tracking utility. Collects resource infromation for selected PIDs.
That PIDs can be added or removed dynamically
'''
from apscheduler.scheduler import Scheduler
from optparse import OptionParser
from threading import Thread
import time
import psutil
import logging
import socket
import string
import daemon
import lockfile.pidlockfile


class Collector(object):
    '''Collects process information by using psutil'''

    LOG = logging.getLogger('pt.collector')
    KEYS = ['num_ctx_switches', \
            'cpu_percent', \
            'cpu_times', \
            'io_counters', \
            'num_threads', \
            'memory_percent', \
            'ext_memory_info']

    def __init__(self, pid, name):
        self.process = psutil.Process(int(pid))
        self.name = name

    def collect(self):
        '''
        Returns process information as a dict of metrics
        Agregated (sum) with childs if any.
        '''
        try:
            Collector.LOG.debug("Collecting info for %s" % self.name)
            results = [self._process_info(process) for process in self.process.get_children(True)]
            results.append(self._process_info(self.process))
            Collector.LOG.debug("Collected %d results for %s" % (len(results), self.name))
            res = Collector.sum_dicts(results)
        except:
            Collector.LOG.exception("Failed to collect metrics")
        return res

    @staticmethod
    def sum_dicts(dicts):
        '''sums dicts by key'''
        return reduce(lambda a, b: dict( (key, a.get(key, 0)+b.get(key, 0)) for key in set(a)|set(b) ), dicts)

    def _process_info(self, process):
        '''Returns info for specific process as a dict of metrics'''
        Collector.LOG.debug("Collecting metrics for %s" % process.pid)
        results = {}
        try:
            res_dict = process.as_dict()
            for key in Collector.KEYS:
                if key in res_dict.keys():
                    if type(res_dict[key]) in [float, int]:
                        results["%s.%s" % (self.name, key)] = res_dict[key]
                    else:
                        try:
                            metrics = res_dict[key]._asdict()
                        except AttributeError:
                            pass
                        for m_key in metrics.keys():
                            results["%s.%s.%s" % (self.name, key, m_key)] = metrics[m_key]
                else:
                    Collector.LOG.warning("Metric %s not found", key)
        except psutil.NoSuchProcess:
            Collector.LOG.exception("No such process")
        except:
            Collector.LOG.exception("Error occured while collecting metrics")
        return results


class TrackerManager(object):
    '''Manages process information collection for multiple processes'''
    LOG = logging.getLogger('pt.tracker_manager')

    def __init__(self, interval):
        self.pids = {}
        self.listeners = []
        self.scheduler = Scheduler()
        self.scheduler.add_interval_job(self.tracking_job, seconds=interval)
        self.scheduler.start()

    def add_listener(self, listener):
        '''Add listener that will receive metrics'''
        self.listeners.append(listener)

    def track(self, pid, name):
        '''Start tracking for process, with selected metric sub-name'''
        TrackerManager.LOG.info("Start tracking for %s/%s", pid, name)
        try:
            process = Collector(pid, name)
            self.pids[pid] = process
        except psutil.NoSuchProcess:
            TrackerManager.LOG.exception("No such process")

    def untrack(self, pid):
        '''Stop tracking process (PID == pid)'''
        try:
            TrackerManager.LOG.info("Stop tracking for %s/%s", pid, self.pids[pid].name)
            del self.pids[pid]
        except KeyError:
            TrackerManager.LOG.warning("PID %s was not tracked", pid)

    def tracking_job(self):
        '''a job that tracks for processes'''
        TrackerManager.LOG.debug("Tracked pids: %s\n", ' '.join(self.pids))
        results = {}
        for pid in self.pids.keys():
            if psutil.pid_exists(int(pid)):
                TrackerManager.LOG.debug("Adding info for %s", pid)
                results.update(self.pids[pid].collect())
            else:
                TrackerManager.LOG.info("Process with PID %s not exist anymore. Stop tracking it...", pid)
                self.untrack(pid)
        TrackerManager.LOG.debug("Submitting %d results", len(results))
        self.submit(results)

    def submit(self, results):
        '''publish results to listeners'''
        for listener in self.listeners:
            listener.submit(results)


class LoggerListener(object):
    '''Listener that writes metrics to log'''
    def __init__(self, name):
        self.logger = logging.getLogger("pt.trace.%s" % name)

    def submit(self, results):
        '''publish results to log'''
        for metric in results.keys():
            self.logger.info("%s\t%s\t%d" % \
                (metric, results[metric], time.time()))


class GraphiteListener(object):
    '''Listener that writes metrics to Graphite'''
    LOG = logging.getLogger('pt.graphite_listener')

    def __init__(self, prefix, address, port):
        self.address = address
        self.port = port
        self.prefix = prefix
        GraphiteListener.LOG.debug("Created a Graphite listener with address = '%s', port = '%s', prefix = '%s'" % (address, port, prefix))

    def _submit_task(self, results):
        '''result submit task for threaded submitter'''
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.connect((self.address, int(self.port)))
            for metric in results.keys():
                sock.sendall("%s.%s\t%s\t%d\n" % \
                    (self.prefix, metric, results[metric], time.time()))
            GraphiteListener.LOG.debug("Sent metrics to %s:%s", (self.address, self.port))
        except:
            GraphiteListener.LOG.exception("Failed to send metrics to %s:%s", (self.address, self.port))
        finally:
            sock.close()

    def submit(self, results):
        '''publish results to Graphite'''
        GraphiteListener.LOG.debug("Trying to send metrics to server...")
        Thread(target=self._submit_task, args=(results,)).start()


class App(object):
    '''Application class. Parse options and serve requests'''
    def __init__(self, opts):
        self.opts = opts
        if self.opts.verbose:
            log_level = logging.DEBUG
        else:
            log_level = logging.INFO
        self.logger = logging.getLogger('pt')
        self.logger.setLevel(log_level)
        #fh = logging.StreamHandler()
        fh = logging.FileHandler(self.opts.logfile)
        fh.setLevel(log_level)
        formatter = logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s')
        fh.setFormatter(formatter)
        self.logger.addHandler(fh)
        self.t_m = TrackerManager(int(self.opts.interval))
        if(self.opts.log_enabled):
            self.logger.info("Adding logger listener")
            self.t_m.add_listener(LoggerListener("metrics"))
        if self.opts.graphite:
            self.logger.info("Adding graphite listener(s)")
            for address in self.opts.graphite_address.split(','):
                self.t_m.add_listener(GraphiteListener(self.opts.graphite_prefix, address, self.opts.graphite_port))

    def _serve(self, conn):
        '''talk with client'''
        while 1:
            data = conn.recv(4096)
            if not data:
                break
            for line in data.splitlines():
                req = line.rstrip('\r\n')
                try:
                    command, pid, name = req.split(' ')
                    if command == 'track':
                        self.t_m.track(pid, name)
                        conn.sendall('OK %s\n' % req)
                    elif command == 'untrack':
                        self.t_m.untrack(pid)
                        conn.sendall('OK %s\n' % req)
                    else:
                        conn.sendall('FAIL %s\n' % req)
                except ValueError:
                    conn.sendall('FAIL %s\n**USAGE:\n\t\
                        track <pid> <key> -- to start tracking pid\n\t\
                        untrack <pid> <key> -- to stop tracking pid\n' % req)

    def run(self):
        '''main function'''
        if(self.opts.version):
            print 'process-tracker-1.6'
            return 0
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.bind(("0.0.0.0", int(self.opts.port)))
        sock.listen(0)
        while 1:
            try:
                self.logger.debug("Waiting for connection...")
                conn, _ = sock.accept()
                self.logger.debug("Got a connection, gonna serve it...")
                self._serve(conn)
            except(SystemExit, KeyboardInterrupt):
                self.logger.info("Exiting, because interrupted.")
                break
            except:
                self.logger.exception("Unkown error in manage server loop")
            finally:
                self.logger.debug("Closing managing connection")
                conn.close()


def parse_options():
    '''parse command line options'''
    argparser = OptionParser()
    argparser.add_option('-p', '--port',
                        help='a port to listen',
                        dest='port',
                        default='6666'
                        )
    argparser.add_option('-l', '--log',
                        help='enable logging metrics',
                        action='store_true',
                        dest='log_enabled',
                        default=False
                        )
    argparser.add_option('-L', '--log-file',
                        help='log file',
                        dest='logfile',
                        default='/var/log/process-tracker/process-tracker.log'
                        )
    argparser.add_option('-r', '--graphite-address',
                        help='graphite server address (use comma for multiple addresses)',
                        dest='graphite_address',
                        default='localhost'
                        )
    argparser.add_option('-R', '--graphite-port',
                        help='graphite server port',
                        dest='graphite_port',
                        default='2024'
                        )
    argparser.add_option('-i', '--interval',
                        help='collection interval in seconds',
                        dest='interval',
                        default='1'
                        )
    hostname = socket.gethostname().translate(string.maketrans(".", "_"))
    argparser.add_option('-P', '--graphite-prefix',
                        help='graphite prefix',
                        dest='graphite_prefix',
                        default='one_sec.process-tracker.%s' % hostname
                        )
    argparser.add_option("-g", "--use-graphite",
                  help="report metrics to graphite",
                  action="store_true",
                  dest="graphite",
                  default=False
                  )
    argparser.add_option("-v", "--version",
                  help="show version and exit",
                  action="store_true",
                  dest="version",
                  default=False
                  )
    argparser.add_option("-V", "--verbose",
                  help="set log level to DEBUG",
                  action="store_true",
                  dest="verbose",
                  default=False
                  )
    return argparser.parse_args()[0]
if __name__ == "__main__":
    OPTIONS = parse_options()
    CONTEXT = daemon.DaemonContext(detach_process = True, pidfile = lockfile.pidlockfile.PIDLockFile("/var/run/process-tracker.pid"))
    CONTEXT.open()
    APP = App(OPTIONS)
    try:
        APP.run()
    finally:
        CONTEXT.close()
